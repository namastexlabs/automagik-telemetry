> [!WARNING]
> **This document has been deprecated and moved to the archive.**
> 
> ðŸ“ **New Location:** See [docs/INDEX.md](../INDEX.md) for updated documentation.
> 
> **Replacements:**
> - Configuration: [docs/USER_GUIDES/CONFIGURATION.md](../USER_GUIDES/CONFIGURATION.md)
> - Quick Start: [docs/GETTING_STARTED.md](../GETTING_STARTED.md)
> - Backends: [docs/USER_GUIDES/BACKENDS.md](../USER_GUIDES/BACKENDS.md)
> - Testing: [docs/DEVELOPER_GUIDES/TESTING.md](../DEVELOPER_GUIDES/TESTING.md)
> - Architecture: [docs/DEVELOPER_GUIDES/ARCHITECTURE.md](../DEVELOPER_GUIDES/ARCHITECTURE.md)
> - Privacy: [docs/USER_GUIDES/PRIVACY.md](../USER_GUIDES/PRIVACY.md)
> 
> This file is kept for historical reference only.

---

[Original content below...]

# Integration Tests Guide

This document describes the comprehensive integration tests for the Automagik Telemetry SDKs and how to run them.

## Overview

Integration tests verify that the SDKs work correctly in real-world scenarios:

- **FastAPI/Express Integration**: Test telemetry in actual HTTP servers
- **High-Throughput**: Verify sustained high load (1000+ events/sec)
- **Real OTLP Collector**: Test against actual backend at `https://telemetry.namastex.ai`
- **Memory Leak Detection**: Long-running tests to verify no memory leaks
- **Concurrent Operations**: Verify thread-safety and async compatibility

## Python Integration Tests

### Setup

Install integration test dependencies:

```bash
cd python

# Install dev dependencies (includes pytest-timeout)
pip install -e ".[dev]"

# Install integration test dependencies (FastAPI, httpx, psutil)
pip install -e ".[integration]"
```

### Running Tests

#### Run All Integration Tests

```bash
# Run all integration tests (may take several minutes)
pytest -v -m integration

# Run with verbose output
pytest -v -s -m integration
```

#### Run Specific Test Files

```bash
# FastAPI integration
pytest -v tests/test_integration_fastapi.py

# High-throughput tests
pytest -v tests/test_integration_throughput.py

# Real OTLP collector tests (requires network)
pytest -v tests/test_integration_otlp.py

# Memory leak detection
pytest -v tests/test_integration_memory.py
```

#### Run Specific Test

```bash
# Run single test
pytest -v tests/test_integration_fastapi.py::test_fastapi_concurrent_requests

# Run with print statements visible
pytest -v -s tests/test_integration_otlp.py::test_send_trace_to_collector
```

#### Skip Integration Tests

Integration tests are marked and can be skipped:

```bash
# Run only unit tests (skip integration)
pytest -v -m "not integration"

# Run all tests except network-dependent ones
pytest -v -m "not network"
```

### Test Files

#### 1. `test_integration_fastapi.py`

Tests FastAPI integration with realistic HTTP request/response cycles.

**Key Tests:**
- Basic FastAPI request with telemetry
- Async endpoint with latency tracking
- Concurrent requests (100+ simultaneous)
- Telemetry overhead measurement
- Event loop blocking verification

**Run:**
```bash
pytest -v tests/test_integration_fastapi.py
```

**Requirements:**
- `fastapi>=0.109.0`
- `httpx>=0.26.0`

#### 2. `test_integration_throughput.py`

Tests sustained high throughput and batch efficiency.

**Key Tests:**
- Burst of 1000 events
- Sustained throughput (1000 events/sec for 10s)
- Concurrent producers (10 threads)
- Mixed signal types (traces, metrics, logs)
- Queue management under load
- Batch efficiency comparison
- Compression efficiency

**Run:**
```bash
pytest -v tests/test_integration_throughput.py
```

**Requirements:**
- `psutil>=5.9.0` (for memory tests)

#### 3. `test_integration_otlp.py`

Tests real network communication with OTLP collector.

**Key Tests:**
- Send traces to real collector
- Send metrics (gauge, counter, histogram)
- Send logs (all severity levels)
- Large payloads with compression
- Concurrent sends
- Retry logic
- Custom endpoint configuration

**Run:**
```bash
# Requires network access
pytest -v -m network tests/test_integration_otlp.py

# With custom endpoint
AUTOMAGIK_TELEMETRY_ENDPOINT=https://custom.endpoint.com pytest -v tests/test_integration_otlp.py
```

**Requirements:**
- Network connectivity
- Access to `https://telemetry.namastex.ai`

**Environment Variables:**
- `AUTOMAGIK_TELEMETRY_ENDPOINT`: Override collector endpoint (default: https://telemetry.namastex.ai)
- `AUTOMAGIK_TELEMETRY_VERBOSE`: Enable verbose logging (true/false)

#### 4. `test_integration_memory.py`

Tests for memory leaks and resource cleanup.

**Key Tests:**
- No memory leak with 10,000 simple events
- Memory returns to baseline after flush
- No thread leaks
- Sustained load memory stability (30s continuous events)
- Large payload memory usage
- Mixed signal types memory usage
- Repeated enable/disable cycles
- Queue memory bounds

**Run:**
```bash
# Requires psutil
pytest -v tests/test_integration_memory.py

# Run with garbage collection enabled (for better leak detection)
python -c "import gc; gc.set_debug(gc.DEBUG_LEAK); import pytest; pytest.main(['-v', 'tests/test_integration_memory.py'])"
```

**Requirements:**
- `psutil>=5.9.0`

**Note:** Some tests may take several minutes. Extended timeout is configured.

## TypeScript Integration Tests

### Setup

Install dependencies:

```bash
cd typescript

# Install all dependencies
pnpm install

# or with npm
npm install
```

### Running Tests

#### Run All Integration Tests

```bash
# Run all tests (includes integration)
pnpm test

# Run only integration tests
pnpm test -- integration.test.ts

# Run with verbose output
pnpm test -- --verbose integration.test.ts
```

#### Run Specific Test Suite

```bash
# Run specific describe block
pnpm test -- --testNamePattern="Express/Fastify Integration"

# Run specific test
pnpm test -- --testNamePattern="should handle burst of 1000 events"
```

#### CI Environment

Integration tests are skipped in CI by default. To run them in CI:

```bash
# Enable integration tests in CI
RUN_INTEGRATION_TESTS=true pnpm test
```

### Test File: `tests/integration.test.ts`

Comprehensive integration tests mirroring Python tests.

**Key Test Suites:**

1. **Express/Fastify Integration**
   - Middleware pattern with telemetry
   - Concurrent request handling (100 requests)

2. **High-Throughput Tests**
   - Burst of 1000 events
   - Sustained throughput (500 events/sec for 5s)
   - Mixed signal types at high volume

3. **Real OTLP Collector Integration**
   - Send traces to real collector
   - Send metrics (all types)
   - Send logs (all severity levels)
   - Large payloads with compression

4. **Memory Leak Detection**
   - Simple events (5000 events)
   - Memory returns to baseline after flush
   - Sustained load (10s continuous events)

5. **Error Handling**
   - Graceful network error handling
   - Error tracking

6. **Configuration**
   - Custom endpoints
   - Batch configuration

**Run:**
```bash
# All integration tests
pnpm test -- integration.test.ts

# Specific suite
pnpm test -- --testNamePattern="Real OTLP Collector"

# With memory profiling (requires --expose-gc)
node --expose-gc node_modules/.bin/jest integration.test.ts
```

**Environment Variables:**
- `AUTOMAGIK_TELEMETRY_ENDPOINT`: Override collector endpoint
- `AUTOMAGIK_TELEMETRY_ENABLED`: Enable telemetry (true/false)
- `AUTOMAGIK_TELEMETRY_VERBOSE`: Enable verbose logging
- `RUN_INTEGRATION_TESTS`: Run integration tests in CI (true/false)

## Test Configuration

### Python Test Markers

Defined in `pyproject.toml`:

- `integration`: Integration tests requiring network/external services
- `network`: Tests requiring network connectivity
- `timeout`: Custom timeout for long-running tests
- `performance`: Performance benchmark tests

### Environment Variables

Both SDKs support these environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `AUTOMAGIK_TELEMETRY_ENABLED` | Enable/disable telemetry | `false` |
| `AUTOMAGIK_TELEMETRY_ENDPOINT` | Collector endpoint | `https://telemetry.namastex.ai` |
| `AUTOMAGIK_TELEMETRY_VERBOSE` | Verbose logging | `false` |
| `AUTOMAGIK_TELEMETRY_TIMEOUT` | Request timeout (seconds) | `5` |

## CI/CD Integration

### GitHub Actions Example

```yaml
name: Integration Tests

on:
  pull_request:
  schedule:
    - cron: '0 0 * * *'  # Daily

jobs:
  python-integration:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd python
          pip install -e ".[dev,integration]"

      - name: Run integration tests
        run: |
          cd python
          pytest -v -m integration
        env:
          AUTOMAGIK_TELEMETRY_ENABLED: true

  typescript-integration:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: |
          cd typescript
          pnpm install

      - name: Run integration tests
        run: |
          cd typescript
          pnpm test -- integration.test.ts
        env:
          RUN_INTEGRATION_TESTS: true
          AUTOMAGIK_TELEMETRY_ENABLED: true
```

## Troubleshooting

### Python

**Issue:** Tests fail with `ModuleNotFoundError: No module named 'fastapi'`

**Solution:** Install integration dependencies:
```bash
pip install -e ".[integration]"
```

**Issue:** Memory tests fail

**Solution:** Install psutil:
```bash
pip install psutil
```

**Issue:** Network tests timeout

**Solution:** Check network connectivity and endpoint:
```bash
curl -v https://telemetry.namastex.ai/v1/traces
```

### TypeScript

**Issue:** Integration tests skipped in CI

**Solution:** Set environment variable:
```bash
RUN_INTEGRATION_TESTS=true pnpm test
```

**Issue:** Memory tests not accurate

**Solution:** Run with garbage collection enabled:
```bash
node --expose-gc node_modules/.bin/jest integration.test.ts
```

**Issue:** Tests timeout

**Solution:** Increase Jest timeout in test file or via CLI:
```bash
pnpm test -- --testTimeout=30000
```

## Performance Benchmarks

Expected performance (on modern hardware):

### Python

- **Event generation**: 10,000+ events/sec
- **Flush latency**: < 500ms for 100 events
- **Memory overhead**: < 5 MB for 10,000 events
- **Concurrent requests**: 100 requests in < 2s

### TypeScript

- **Event generation**: 8,000+ events/sec
- **Flush latency**: < 500ms for 100 events
- **Memory overhead**: < 10 MB for 5,000 events
- **Concurrent requests**: 100 requests in < 2s

## Best Practices

1. **Run integration tests before releases**: Verify SDK works with real infrastructure
2. **Monitor test performance**: Track execution time to detect regressions
3. **Use custom endpoints for testing**: Don't spam production with test data
4. **Enable verbose mode for debugging**: Set `AUTOMAGIK_TELEMETRY_VERBOSE=true`
5. **Run memory tests periodically**: Catch leaks early
6. **Test with realistic payloads**: Use actual data shapes from your application

## Contributing

When adding new integration tests:

1. Mark tests appropriately (`@pytest.mark.integration` or `describeIntegration`)
2. Add reasonable timeouts for long-running tests
3. Clean up resources in teardown (flush, disable)
4. Document test purpose and requirements
5. Test both success and failure scenarios
6. Add test to this documentation

## Support

For issues or questions:

- GitHub Issues: https://github.com/namastexlabs/automagik-telemetry/issues
- Documentation: https://docs.automagik.ai/telemetry
- Email: team@namastex.ai
